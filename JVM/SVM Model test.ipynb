{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVM Model test.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sGnu-QO0gwkx","colab_type":"text"},"source":["##Import librairies"]},{"cell_type":"code","metadata":{"id":"ybt-q3Yuf2cz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":101},"outputId":"7e27f00d-8742-4056-f203-faabdae41df4","executionInfo":{"status":"ok","timestamp":1571650169460,"user_tz":-120,"elapsed":622,"user":{"displayName":"simon agnabal","photoUrl":"","userId":"15640420778883463574"}}},"source":["import pickle\n","import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import punkt\n","from nltk.corpus.reader import wordnet\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","nltk.download('stopwords')\n","nltk.download('wordnet')"],"execution_count":31,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"BNaL_9djg4DM","colab_type":"text"},"source":["##Import models (trained model + text traitement model)"]},{"cell_type":"code","metadata":{"id":"Sz5wBVePg96O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":138},"outputId":"e6579306-7e32-43c1-ca53-a804e6f5b548","executionInfo":{"status":"ok","timestamp":1571650169697,"user_tz":-120,"elapsed":846,"user":{"displayName":"simon agnabal","photoUrl":"","userId":"15640420778883463574"}}},"source":["#SVC\n","with open(\"best_svc.pickle\", 'rb') as data:\n","  svc_model = pickle.load(data)\n","  \n","#Text traitement model\n","with open(\"tfidf.pickle\", 'rb') as data:\n","  tfidf = pickle.load(data)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator SVC from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n","  UserWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"s9tgS-3pi5UR","colab_type":"text"},"source":["## Category mapping and Text traitement workflow"]},{"cell_type":"code","metadata":{"id":"84VqpOB1jApG","colab_type":"code","colab":{}},"source":["category_codes = {\n","    'business': 0,\n","    'entaertainement': 1,\n","    'politics': 2,\n","    'sport': 3,\n","    'tech':4\n","}\n","\n","punctuation_signs = list(\"?:!.,;\")\n","stop_words = list(stopwords.words('french'))\n","\n","def create_features_from_text(text):\n","    \n","    # Dataframe creation\n","    lemmatized_text_list = []\n","    df = pd.DataFrame(columns=['Content'])\n","    df.loc[0] = text\n","    df['Content_Parsed_1'] = df['Content'].str.replace(\"\\r\", \" \")\n","    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n","    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"    \", \" \")\n","    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace('\"', '')\n","    df['Content_Parsed_2'] = df['Content_Parsed_1'].str.lower()\n","    df['Content_Parsed_3'] = df['Content_Parsed_2']\n","    for punct_sign in punctuation_signs:\n","        df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')\n","    df['Content_Parsed_4'] = df['Content_Parsed_3'].str.replace(\"'s\", \"\")\n","    wordnet_lemmatizer = WordNetLemmatizer()\n","    lemmatized_list = []\n","    text = df.loc[0]['Content_Parsed_4']\n","    text_words = text.split(\" \")\n","    for word in text_words:\n","        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n","    lemmatized_text = \" \".join(lemmatized_list)    \n","    lemmatized_text_list.append(lemmatized_text)\n","    df['Content_Parsed_5'] = lemmatized_text_list\n","    df['Content_Parsed_6'] = df['Content_Parsed_5']\n","    for stop_word in stop_words:\n","        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n","        df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')\n","    df = df['Content_Parsed_6']\n","    df = df.rename(columns={'Content_Parsed_6': 'Content_Parsed'})\n","    \n","    # TF-IDF\n","    features = tfidf.transform(df).toarray()\n","    \n","    return features\n","  \n","  \n","def get_category_name(category_id):\n","    for category, id_ in category_codes.items():    \n","        if id_ == category_id:\n","            return category\n","          \n","def predict_from_text(text):\n","    \n","    # Predict using the input model\n","    prediction_svc = svc_model.predict(create_features_from_text(text))[0]\n","    prediction_svc_proba = svc_model.predict_proba(create_features_from_text(text))[0]\n","    \n","    # Return result\n","    category_svc = get_category_name(prediction_svc)\n","    \n","    print(\"The predicted category using the SVM model is %s.\" %(category_svc) )\n","    print(\"The conditional probability is: %a\" %(prediction_svc_proba.max()*100))\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dJYttdWbo66b","colab_type":"text"},"source":["##Test prediction"]},{"cell_type":"code","metadata":{"id":"OQVQgXCso6Yf","colab_type":"code","colab":{}},"source":["text = \"\"\"\n","\n","The center-right party Ciudadanos closed a deal on Wednesday with the support of the conservative Popular Party (PP) to take control of the speaker’s committee in the Andalusian parliament, paving the way for the regional PP leader, Juan Manuel Moreno, to stand as the candidate for premier of the southern Spanish region. The move would see the Socialist Party (PSOE) lose power in the Junta, as the regional government is known, for the first time in 36 years.\n","\n","Talks in Andalusia have been ongoing since regional polls were held on December 2. The PSOE, led by incumbent premier Susana Díaz, had been expected to win the early elections, but in a shock result the party took the most seats in parliament, 33, but fell well short of a majority of 55. It was their worst result in the region since Spain returned to democracy. The PP came in second, with 26 seats, while Ciudadanos were third with 21. The major surprise was the strong performance of far-right group Vox, which won more than 391,000 votes (10.9%), giving it 12 deputies. The anti-immigration group is the first of its kind to win seats in a Spanish parliament since the end of the Francisco Franco dictatorship. It now holds the key to power in Andalusia, given that its votes, added to those of the PP and Ciudadanos, constitute an absolute majority.\n","\n","The move would see the Socialist Party lose power in the region for the first time in 36 years\n","\n","On Thursday, Marta Bosquet of Ciudadanos was voted in as the new speaker of the Andalusian parliament thanks to 59 votes from her party, the PP and Vox. The other candidate, Inmaculada Nieto of Adelante Andalucía, secured 50 votes – from her own party and 33 from the PSOE.\n","\n","The speaker’s role in the parliament is key for the calling of an investiture vote and for the selection of the candidate for premier.\n","\n","Officially, the talks as to the make up of a future government have yet to start, but in reality they are well advanced, according to sources from both the PP and Ciudadanos. The leader of the Andalusian PP is banking on being voted into power around January 16 and wants the majority of his Cabinet to be decided “five days before the investiture vote.”\n","\n","The speaker’s role in the parliament is key for the calling of an investiture vote and for the selection of the candidate for premier\n","\n","The PP, which was ousted from power by the PSOE in the national government in June, is keen to take the reins of power in Andalusia as soon as possible. The difficulties that Ciudadanos has faced to justify the necessary inclusion of Vox in the talks, has slowed down progress. Rather than align itself with the far right party, the group – which began life in Catalonia in response to the independence drive, but soon launched onto the national stage – had sought a deal with Adelante Andalucía.\n","\n","Wednesday was a day of intense talks among the parties in a bid to find a solution that would keep everyone happy. But at 9pm last night, Adelante Andalucía announced that it would not be part of “any deal” and that would instead vote for its own candidates to the speaker’s committee in order to “face up to the right wing and the extreme right.”\n","\n","The PSOE, meanwhile, argues that having won the elections with a seven-seat lead over the PP gives it the legitimacy to aspire to the control of the regional government and the parliament, and to maintain its positions on the speaker’s committee.\n","\n","\n","\n","\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7AduMx28pCfU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"c85420f1-084f-4ebf-a8f4-c59daf13ca44","executionInfo":{"status":"ok","timestamp":1571650213470,"user_tz":-120,"elapsed":525,"user":{"displayName":"simon agnabal","photoUrl":"","userId":"15640420778883463574"}}},"source":["predict_from_text(text)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["The predicted category using the SVM model is politics.\n","The conditional probability is: 92.18788565906785\n"],"name":"stdout"}]}]}